model="LLAMA-3.1"
params="8B"
inp_seq_len=1024
new_tokens=64512
batch_size=2
iter=1
threads=50
allocator="malloc"
huge_pages=0
hbm_first=0
tier=1
hbm_dram_log="temp.log"
n_l_hbm=32
n_l_mig=0
kv_static_pin=0